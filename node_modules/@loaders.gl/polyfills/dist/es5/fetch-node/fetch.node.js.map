{"version":3,"sources":["../../../src/fetch-node/fetch.node.js"],"names":["isDataURL","url","startsWith","isRequestURL","fetchNode","options","arrayBuffer","mimeType","response","Response","headers","syntheticResponseHeaders","originalUrl","endsWith","slice","body","getHeaders","getStatus","status","statusText","String","httpResponse","statusCode","statusMessage","additionalHeaders","httpHeaders","key","header","toLowerCase","contentLength","getContentLength","Number","isFinite","Object","assign","Headers","length","noqueryUrl","split","stats","fs","statSync","size","error"],"mappings":";;;;;;;;;;;;;AAAA;;AACA;;AACA;;AAEA;;AACA;;AAEA,IAAMA,SAAS,GAAG,SAAZA,SAAY,CAAAC,GAAG;AAAA,SAAIA,GAAG,CAACC,UAAJ,CAAe,OAAf,CAAJ;AAAA,CAArB;;AACA,IAAMC,YAAY,GAAG,SAAfA,YAAe,CAAAF,GAAG;AAAA,SAAIA,GAAG,CAACC,UAAJ,CAAe,OAAf,KAA2BD,GAAG,CAACC,UAAJ,CAAe,QAAf,CAA/B;AAAA,CAAxB;;SAO8BE,S;;;;;+EAAf,iBAAyBH,GAAzB,EAA8BI,OAA9B;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA,iBAIPL,SAAS,CAACC,GAAD,CAJF;AAAA;AAAA;AAAA;;AAAA,6BAKuB,mCAAcA,GAAd,CALvB,EAKFK,WALE,kBAKFA,WALE,EAKWC,QALX,kBAKWA,QALX;AAMHC,YAAAA,QANG,GAMQ,IAAIC,oBAAJ,CAAaH,WAAb,EAA0B;AACzCI,cAAAA,OAAO,EAAE;AAAC,gCAAgBH,QAAjB;AAA2BN,gBAAAA,GAAG,EAAHA;AAA3B;AADgC,aAA1B,CANR;AAAA,6CASFO,QATE;;AAAA;AAaLG,YAAAA,wBAbK,GAasB,EAbtB;AAcLC,YAAAA,WAdK,GAcSX,GAdT;;AAeX,gBAAIA,GAAG,CAACY,QAAJ,CAAa,KAAb,CAAJ,EAAyB;AACvBZ,cAAAA,GAAG,GAAGA,GAAG,CAACa,KAAJ,CAAU,CAAV,EAAa,CAAC,CAAd,CAAN;AACAH,cAAAA,wBAAwB,CAAC,kBAAD,CAAxB,GAA+C,MAA/C;AACD;;AAlBU;AAAA,mBAqBQ,mCAAiBC,WAAjB,EAA8BP,OAA9B,CArBR;;AAAA;AAqBLU,YAAAA,IArBK;AAsBLL,YAAAA,OAtBK,GAsBKM,UAAU,CAACf,GAAD,EAAMc,IAAN,EAAYJ,wBAAZ,CAtBf;AAAA,yBAuBkBM,SAAS,CAACF,IAAD,CAvB3B,EAuBJG,MAvBI,cAuBJA,MAvBI,EAuBIC,UAvBJ,cAuBIA,UAvBJ;AAAA,6CAwBJ,IAAIV,oBAAJ,CAAaM,IAAb,EAAmB;AAACL,cAAAA,OAAO,EAAPA,OAAD;AAAUQ,cAAAA,MAAM,EAANA,MAAV;AAAkBC,cAAAA,UAAU,EAAVA,UAAlB;AAA8BlB,cAAAA,GAAG,EAAHA;AAA9B,aAAnB,CAxBI;;AAAA;AAAA;AAAA;AAAA,6CA2BJ,IAAIQ,oBAAJ,CAAa,IAAb,EAAmB;AAACS,cAAAA,MAAM,EAAE,GAAT;AAAcC,cAAAA,UAAU,EAAEC,MAAM,aAAhC;AAAyCnB,cAAAA,GAAG,EAAHA;AAAzC,aAAnB,CA3BI;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAkCf,SAASgB,SAAT,CAAmBI,YAAnB,EAAiC;AAC/B,MAAIA,YAAY,CAACC,UAAjB,EAA6B;AAC3B,WAAO;AAACJ,MAAAA,MAAM,EAAEG,YAAY,CAACC,UAAtB;AAAkCH,MAAAA,UAAU,EAAEE,YAAY,CAACE,aAAb,IAA8B;AAA5E,KAAP;AACD;;AACD,SAAO;AAACL,IAAAA,MAAM,EAAE,GAAT;AAAcC,IAAAA,UAAU,EAAE;AAA1B,GAAP;AACD;;AAED,SAASH,UAAT,CAAoBf,GAApB,EAAyBoB,YAAzB,EAA+D;AAAA,MAAxBG,iBAAwB,uEAAJ,EAAI;AAC7D,MAAMd,OAAO,GAAG,EAAhB;;AAEA,MAAIW,YAAY,IAAIA,YAAY,CAACX,OAAjC,EAA0C;AACxC,QAAMe,WAAW,GAAGJ,YAAY,CAACX,OAAjC;;AACA,SAAK,IAAMgB,GAAX,IAAkBD,WAAlB,EAA+B;AAC7B,UAAME,MAAM,GAAGF,WAAW,CAACC,GAAD,CAA1B;AACAhB,MAAAA,OAAO,CAACgB,GAAG,CAACE,WAAJ,EAAD,CAAP,GAA6BR,MAAM,CAACO,MAAD,CAAnC;AACD;AACF;;AAGD,MAAI,CAACjB,OAAO,CAAC,gBAAD,CAAZ,EAAgC;AAC9B,QAAMmB,aAAa,GAAGC,gBAAgB,CAAC7B,GAAD,CAAtC;;AACA,QAAI8B,MAAM,CAACC,QAAP,CAAgBH,aAAhB,CAAJ,EAAoC;AAClCnB,MAAAA,OAAO,CAAC,gBAAD,CAAP,GAA4BmB,aAA5B;AACD;AACF;;AAEDI,EAAAA,MAAM,CAACC,MAAP,CAAcxB,OAAd,EAAuBc,iBAAvB;AAEA,SAAO,IAAIW,mBAAJ,CAAYzB,OAAZ,CAAP;AACD;;AAED,SAASoB,gBAAT,CAA0B7B,GAA1B,EAA+B;AAC7B,MAAIE,YAAY,CAACF,GAAD,CAAhB,EAAuB;AAErB,WAAO,IAAP;AACD,GAHD,MAGO,IAAID,SAAS,CAACC,GAAD,CAAb,EAAoB;AAEzB,WAAOA,GAAG,CAACmC,MAAJ,GAAa,QAAQA,MAA5B;AACD;;AAGD,MAAI;AAEF,QAAMC,UAAU,GAAGpC,GAAG,CAACqC,KAAJ,CAAU,GAAV,EAAe,CAAf,CAAnB;;AACA,QAAMC,KAAK,GAAGC,eAAGC,QAAH,CAAYJ,UAAZ,CAAd;;AACA,WAAOE,KAAK,CAACG,IAAb;AACD,GALD,CAKE,OAAOC,KAAP,EAAc,CAEf;;AAED,SAAO,IAAP;AACD","sourcesContent":["import fs from 'fs'; // `fs` will be empty object in browsers (see package.json \"browser\" field).\nimport Response from './response.node';\nimport Headers from './headers.node';\n\nimport {decodeDataUri} from './utils/decode-data-uri.node';\nimport {createReadStream} from './utils/stream-utils.node';\n\nconst isDataURL = url => url.startsWith('data:');\nconst isRequestURL = url => url.startsWith('http:') || url.startsWith('https:');\n\n/**\n * Emulation of Browser fetch for Node.js\n * @param url\n * @param options\n */\nexport default async function fetchNode(url, options) {\n  try {\n    // Handle data urls in node, to match `fetch``\n    // Note - this loses the MIME type, data URIs are handled directly in fetch\n    if (isDataURL(url)) {\n      const {arrayBuffer, mimeType} = decodeDataUri(url);\n      const response = new Response(arrayBuffer, {\n        headers: {'content-type': mimeType, url}\n      });\n      return response;\n    }\n\n    // Automatically decompress gzipped files with .gz extension\n    const syntheticResponseHeaders = {};\n    const originalUrl = url;\n    if (url.endsWith('.gz')) {\n      url = url.slice(0, -3);\n      syntheticResponseHeaders['content-encoding'] = 'gzip';\n    }\n\n    // Need to create the stream in advance since Response constructor needs to be sync\n    const body = await createReadStream(originalUrl, options);\n    const headers = getHeaders(url, body, syntheticResponseHeaders);\n    const {status, statusText} = getStatus(body);\n    return new Response(body, {headers, status, statusText, url});\n  } catch (error) {\n    // TODO - what error code to use here?\n    return new Response(null, {status: 400, statusText: String(error), url});\n  }\n}\n\n// HELPER FUNCTIONS\n// PRIVATE\n\nfunction getStatus(httpResponse) {\n  if (httpResponse.statusCode) {\n    return {status: httpResponse.statusCode, statusText: httpResponse.statusMessage || 'NA'};\n  }\n  return {status: 200, statusText: 'OK'};\n}\n\nfunction getHeaders(url, httpResponse, additionalHeaders = {}) {\n  const headers = {};\n\n  if (httpResponse && httpResponse.headers) {\n    const httpHeaders = httpResponse.headers;\n    for (const key in httpHeaders) {\n      const header = httpHeaders[key];\n      headers[key.toLowerCase()] = String(header);\n    }\n  }\n\n  // Fix up content length if we can for best progress experience\n  if (!headers['content-length']) {\n    const contentLength = getContentLength(url);\n    if (Number.isFinite(contentLength)) {\n      headers['content-length'] = contentLength;\n    }\n  }\n\n  Object.assign(headers, additionalHeaders);\n\n  return new Headers(headers);\n}\n\nfunction getContentLength(url) {\n  if (isRequestURL(url)) {\n    // Needs to be read from actual headers\n    return null;\n  } else if (isDataURL(url)) {\n    // TODO - remove media type etc\n    return url.length - 'data:'.length;\n  }\n  // File URL\n  // TODO - how to handle non-existing file, this presumably just throws\n  try {\n    // strip query params from URL\n    const noqueryUrl = url.split('?')[0];\n    const stats = fs.statSync(noqueryUrl);\n    return stats.size;\n  } catch (error) {\n    // ignore for now\n  }\n\n  return null;\n}\n"],"file":"fetch.node.js"}