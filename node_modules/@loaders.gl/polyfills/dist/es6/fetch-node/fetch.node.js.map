{"version":3,"sources":["../../../src/fetch-node/fetch.node.js"],"names":["fs","Response","Headers","decodeDataUri","createReadStream","isDataURL","url","startsWith","isRequestURL","fetchNode","options","arrayBuffer","mimeType","response","headers","syntheticResponseHeaders","originalUrl","endsWith","slice","body","getHeaders","status","statusText","getStatus","error","String","httpResponse","statusCode","statusMessage","additionalHeaders","httpHeaders","key","header","toLowerCase","contentLength","getContentLength","Number","isFinite","Object","assign","length","noqueryUrl","split","stats","statSync","size"],"mappings":"AAAA,OAAOA,EAAP,MAAe,IAAf;AACA,OAAOC,QAAP,MAAqB,iBAArB;AACA,OAAOC,OAAP,MAAoB,gBAApB;AAEA,SAAQC,aAAR,QAA4B,8BAA5B;AACA,SAAQC,gBAAR,QAA+B,2BAA/B;;AAEA,MAAMC,SAAS,GAAGC,GAAG,IAAIA,GAAG,CAACC,UAAJ,CAAe,OAAf,CAAzB;;AACA,MAAMC,YAAY,GAAGF,GAAG,IAAIA,GAAG,CAACC,UAAJ,CAAe,OAAf,KAA2BD,GAAG,CAACC,UAAJ,CAAe,QAAf,CAAvD;;AAOA,eAAe,eAAeE,SAAf,CAAyBH,GAAzB,EAA8BI,OAA9B,EAAuC;AACpD,MAAI;AAGF,QAAIL,SAAS,CAACC,GAAD,CAAb,EAAoB;AAClB,YAAM;AAACK,QAAAA,WAAD;AAAcC,QAAAA;AAAd,UAA0BT,aAAa,CAACG,GAAD,CAA7C;AACA,YAAMO,QAAQ,GAAG,IAAIZ,QAAJ,CAAaU,WAAb,EAA0B;AACzCG,QAAAA,OAAO,EAAE;AAAC,0BAAgBF,QAAjB;AAA2BN,UAAAA;AAA3B;AADgC,OAA1B,CAAjB;AAGA,aAAOO,QAAP;AACD;;AAGD,UAAME,wBAAwB,GAAG,EAAjC;AACA,UAAMC,WAAW,GAAGV,GAApB;;AACA,QAAIA,GAAG,CAACW,QAAJ,CAAa,KAAb,CAAJ,EAAyB;AACvBX,MAAAA,GAAG,GAAGA,GAAG,CAACY,KAAJ,CAAU,CAAV,EAAa,CAAC,CAAd,CAAN;AACAH,MAAAA,wBAAwB,CAAC,kBAAD,CAAxB,GAA+C,MAA/C;AACD;;AAGD,UAAMI,IAAI,GAAG,MAAMf,gBAAgB,CAACY,WAAD,EAAcN,OAAd,CAAnC;AACA,UAAMI,OAAO,GAAGM,UAAU,CAACd,GAAD,EAAMa,IAAN,EAAYJ,wBAAZ,CAA1B;AACA,UAAM;AAACM,MAAAA,MAAD;AAASC,MAAAA;AAAT,QAAuBC,SAAS,CAACJ,IAAD,CAAtC;AACA,WAAO,IAAIlB,QAAJ,CAAakB,IAAb,EAAmB;AAACL,MAAAA,OAAD;AAAUO,MAAAA,MAAV;AAAkBC,MAAAA,UAAlB;AAA8BhB,MAAAA;AAA9B,KAAnB,CAAP;AACD,GAxBD,CAwBE,OAAOkB,KAAP,EAAc;AAEd,WAAO,IAAIvB,QAAJ,CAAa,IAAb,EAAmB;AAACoB,MAAAA,MAAM,EAAE,GAAT;AAAcC,MAAAA,UAAU,EAAEG,MAAM,CAACD,KAAD,CAAhC;AAAyClB,MAAAA;AAAzC,KAAnB,CAAP;AACD;AACF;;AAKD,SAASiB,SAAT,CAAmBG,YAAnB,EAAiC;AAC/B,MAAIA,YAAY,CAACC,UAAjB,EAA6B;AAC3B,WAAO;AAACN,MAAAA,MAAM,EAAEK,YAAY,CAACC,UAAtB;AAAkCL,MAAAA,UAAU,EAAEI,YAAY,CAACE,aAAb,IAA8B;AAA5E,KAAP;AACD;;AACD,SAAO;AAACP,IAAAA,MAAM,EAAE,GAAT;AAAcC,IAAAA,UAAU,EAAE;AAA1B,GAAP;AACD;;AAED,SAASF,UAAT,CAAoBd,GAApB,EAAyBoB,YAAzB,EAAuCG,iBAAiB,GAAG,EAA3D,EAA+D;AAC7D,QAAMf,OAAO,GAAG,EAAhB;;AAEA,MAAIY,YAAY,IAAIA,YAAY,CAACZ,OAAjC,EAA0C;AACxC,UAAMgB,WAAW,GAAGJ,YAAY,CAACZ,OAAjC;;AACA,SAAK,MAAMiB,GAAX,IAAkBD,WAAlB,EAA+B;AAC7B,YAAME,MAAM,GAAGF,WAAW,CAACC,GAAD,CAA1B;AACAjB,MAAAA,OAAO,CAACiB,GAAG,CAACE,WAAJ,EAAD,CAAP,GAA6BR,MAAM,CAACO,MAAD,CAAnC;AACD;AACF;;AAGD,MAAI,CAAClB,OAAO,CAAC,gBAAD,CAAZ,EAAgC;AAC9B,UAAMoB,aAAa,GAAGC,gBAAgB,CAAC7B,GAAD,CAAtC;;AACA,QAAI8B,MAAM,CAACC,QAAP,CAAgBH,aAAhB,CAAJ,EAAoC;AAClCpB,MAAAA,OAAO,CAAC,gBAAD,CAAP,GAA4BoB,aAA5B;AACD;AACF;;AAEDI,EAAAA,MAAM,CAACC,MAAP,CAAczB,OAAd,EAAuBe,iBAAvB;AAEA,SAAO,IAAI3B,OAAJ,CAAYY,OAAZ,CAAP;AACD;;AAED,SAASqB,gBAAT,CAA0B7B,GAA1B,EAA+B;AAC7B,MAAIE,YAAY,CAACF,GAAD,CAAhB,EAAuB;AAErB,WAAO,IAAP;AACD,GAHD,MAGO,IAAID,SAAS,CAACC,GAAD,CAAb,EAAoB;AAEzB,WAAOA,GAAG,CAACkC,MAAJ,GAAa,QAAQA,MAA5B;AACD;;AAGD,MAAI;AAEF,UAAMC,UAAU,GAAGnC,GAAG,CAACoC,KAAJ,CAAU,GAAV,EAAe,CAAf,CAAnB;AACA,UAAMC,KAAK,GAAG3C,EAAE,CAAC4C,QAAH,CAAYH,UAAZ,CAAd;AACA,WAAOE,KAAK,CAACE,IAAb;AACD,GALD,CAKE,OAAOrB,KAAP,EAAc,CAEf;;AAED,SAAO,IAAP;AACD","sourcesContent":["import fs from 'fs'; // `fs` will be empty object in browsers (see package.json \"browser\" field).\nimport Response from './response.node';\nimport Headers from './headers.node';\n\nimport {decodeDataUri} from './utils/decode-data-uri.node';\nimport {createReadStream} from './utils/stream-utils.node';\n\nconst isDataURL = url => url.startsWith('data:');\nconst isRequestURL = url => url.startsWith('http:') || url.startsWith('https:');\n\n/**\n * Emulation of Browser fetch for Node.js\n * @param url\n * @param options\n */\nexport default async function fetchNode(url, options) {\n  try {\n    // Handle data urls in node, to match `fetch``\n    // Note - this loses the MIME type, data URIs are handled directly in fetch\n    if (isDataURL(url)) {\n      const {arrayBuffer, mimeType} = decodeDataUri(url);\n      const response = new Response(arrayBuffer, {\n        headers: {'content-type': mimeType, url}\n      });\n      return response;\n    }\n\n    // Automatically decompress gzipped files with .gz extension\n    const syntheticResponseHeaders = {};\n    const originalUrl = url;\n    if (url.endsWith('.gz')) {\n      url = url.slice(0, -3);\n      syntheticResponseHeaders['content-encoding'] = 'gzip';\n    }\n\n    // Need to create the stream in advance since Response constructor needs to be sync\n    const body = await createReadStream(originalUrl, options);\n    const headers = getHeaders(url, body, syntheticResponseHeaders);\n    const {status, statusText} = getStatus(body);\n    return new Response(body, {headers, status, statusText, url});\n  } catch (error) {\n    // TODO - what error code to use here?\n    return new Response(null, {status: 400, statusText: String(error), url});\n  }\n}\n\n// HELPER FUNCTIONS\n// PRIVATE\n\nfunction getStatus(httpResponse) {\n  if (httpResponse.statusCode) {\n    return {status: httpResponse.statusCode, statusText: httpResponse.statusMessage || 'NA'};\n  }\n  return {status: 200, statusText: 'OK'};\n}\n\nfunction getHeaders(url, httpResponse, additionalHeaders = {}) {\n  const headers = {};\n\n  if (httpResponse && httpResponse.headers) {\n    const httpHeaders = httpResponse.headers;\n    for (const key in httpHeaders) {\n      const header = httpHeaders[key];\n      headers[key.toLowerCase()] = String(header);\n    }\n  }\n\n  // Fix up content length if we can for best progress experience\n  if (!headers['content-length']) {\n    const contentLength = getContentLength(url);\n    if (Number.isFinite(contentLength)) {\n      headers['content-length'] = contentLength;\n    }\n  }\n\n  Object.assign(headers, additionalHeaders);\n\n  return new Headers(headers);\n}\n\nfunction getContentLength(url) {\n  if (isRequestURL(url)) {\n    // Needs to be read from actual headers\n    return null;\n  } else if (isDataURL(url)) {\n    // TODO - remove media type etc\n    return url.length - 'data:'.length;\n  }\n  // File URL\n  // TODO - how to handle non-existing file, this presumably just throws\n  try {\n    // strip query params from URL\n    const noqueryUrl = url.split('?')[0];\n    const stats = fs.statSync(noqueryUrl);\n    return stats.size;\n  } catch (error) {\n    // ignore for now\n  }\n\n  return null;\n}\n"],"file":"fetch.node.js"}